{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FashionMNISTFeedForwardNeuralNetwork.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "DNOZJJSSs90X"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "from torch import optim, nn\n",
        "import torch.nn.functional as F \n",
        "\n",
        "from torchvision import transforms\n",
        "\n",
        "from torch.utils.data import TensorDataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9VSfMhx7uBnV",
        "outputId": "1af9969f-44fc-4096-8216-220c58c9b570"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f3a91680ad0>"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mYIZWbipuITb",
        "outputId": "31c6aa4f-eaa9-486e-8ec4-22a738c53afc"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"drive/MyDrive/Colab Notebooks/fashion-mnist.csv\"\n",
        "df = pd.read_csv(path)"
      ],
      "metadata": {
        "id": "7KKSG2zKu0xT"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.div(torch.Tensor(np.array(df.iloc[:, 1:])),255).type(torch.FloatTensor)\n",
        "y = torch.Tensor(np.array(df.iloc[:, 0:1].values)).reshape(-1).type(torch.LongTensor)"
      ],
      "metadata": {
        "id": "PNSAYg_O_oXp"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "\n",
        "train_dataset = TensorDataset(X_train, y_train)\n",
        "test_dataset = TensorDataset(X_test,y_test)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "LxAS5IZ2_-Ik"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FashionMNISTNN(nn.Module):\n",
        "    def __init__(self, input_dim, h1,h2, output_dim):\n",
        "        super().__init__()\n",
        "\n",
        "        self.fc1 = nn.Linear(input_dim, h1)\n",
        "        self.fc2 = nn.Linear(h1, h2)\n",
        "        self.fc3 = nn.Linear(h2, output_dim)\n",
        "\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "\n",
        "    def forward(self, x):                           \n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(F.relu(self.fc2(x)))\n",
        "        x = F.softmax(self.fc3(x),dim=1)                  \n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "fpz0LPeVtclW"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_accuracy(a, y):                            \n",
        "    a = torch.max(a, dim=1)[1]\n",
        "    assert not torch.any(torch.isnan(a))\n",
        "    return torch.mean((a == y).float()).item()"
      ],
      "metadata": {
        "id": "OSWDS9luw85Y"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = FashionMNISTNN(784,128,32,10)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=float(0.01))"
      ],
      "metadata": {
        "id": "K-A8nXfbtgNI"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 25\n",
        "loss_history = []\n",
        "accuracy_history = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    epoch_loss = 0\n",
        "    epoch_accuracy = 0\n",
        "    for image, label in train_loader:\n",
        "        z = model(image)\n",
        "        loss = F.cross_entropy(z, label)\n",
        "        accuracy = calc_accuracy(z, label)\n",
        "\n",
        "        optimizer.zero_grad()      \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item() / len(train_dataset) * batch_size\n",
        "        epoch_accuracy += accuracy / len(train_dataset) * batch_size\n",
        "    \n",
        "    loss_history.append(epoch_loss)\n",
        "    accuracy_history.append(epoch_accuracy)\n",
        "\n",
        "    if epoch % 5 == 0:\n",
        "        print(\"Epoch: {}, Loss: {}, Accuracy: {}\".format(epoch, round(epoch_loss, 3), round(100*epoch_accuracy, 3)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-SFzZViwtgsN",
        "outputId": "6058748d-26cf-4480-bb5c-c91f5d456c8b"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, Loss: 1.695, Accuracy: 76.6\n",
            "Epoch: 5, Loss: 1.759, Accuracy: 70.2\n",
            "Epoch: 10, Loss: 1.72, Accuracy: 74.15\n",
            "Epoch: 15, Loss: 1.792, Accuracy: 66.938\n",
            "Epoch: 20, Loss: 1.708, Accuracy: 75.362\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 5\n",
        "avg_loss = 0\n",
        "avg_accuracy = 0\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    epoch_loss = 0\n",
        "    epoch_accuracy = 0\n",
        "    for image, label in test_loader:\n",
        "        z = model(image.float())\n",
        "        loss = F.cross_entropy(z, label)\n",
        "        accuracy = calc_accuracy(z, label)\n",
        "\n",
        "        epoch_loss += loss.item() / len(test_dataset) * batch_size\n",
        "        epoch_accuracy += accuracy / len(test_dataset) * batch_size\n",
        "\n",
        "    avg_loss += epoch_loss / num_epochs\n",
        "    avg_accuracy += epoch_accuracy / num_epochs\n",
        "\n",
        "print(\"Number of Epochs tested: {}, Average loss: {}, Average Accuracy: {}\".format(num_epochs, round(avg_loss, 3), round(100*avg_accuracy, 3)))"
      ],
      "metadata": {
        "id": "bnQhcoyS0OdK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fcee8d11-0fe1-43db-bf63-9ae08ee94b3d"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Epochs tested: 5, Average loss: 1.777, Average Accuracy: 74.36\n"
          ]
        }
      ]
    }
  ]
}